

  
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Applications of Determinants &#8212; Linear Algebra</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/cloud.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noticia+Text|Open+Sans|Droid+Sans+Mono&amp;subset=latin,latin-ext" type="text/css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/jquery.cookie.js"></script>
    <script src="_static/cloud.js"></script>
    <script type="text/javascript" src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
    <script type="text/javascript" src="http://sagecell.sagemath.org/embedded_sagecell.js"></script>
    <script type="text/javascript">
        sagecell.makeSagecell({inputLocation: ".sage_linked",
                               linked: true});
        sagecell.makeSagecell({inputLocation: ".sage_unlinked",
                               linked: false});
    </script>

    <style type="text/css">
        .sagecell .CodeMirror-scroll {
            overflow-y: hidden;
            overflow-x: auto;
        }
        .sagecell .CodeMirror {
            height: auto;
        }
    </style>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Application to Hill Cipher" href="operations_app_Hill_cipher.html" />
    <link rel="prev" title="Practical Calculation of Determinants" href="determinants_practical-calculation.html" />
 
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1">
  </head><body>
  <div class="relbar-top">
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="operations_app_Hill_cipher.html" title="Application to Hill Cipher"
             accesskey="N">next</a> &nbsp; &nbsp;</li>
        <li class="right" >
          <a href="determinants_practical-calculation.html" title="Practical Calculation of Determinants"
             accesskey="P">previous</a> &nbsp; &nbsp;</li>
  <li><a href="index.html">Linear Algebra</a> &#187;</li>
  
        <li class="nav-item nav-item-this"><a href="">Applications of Determinants</a></li> 
      </ul>
    </div>
  </div>
  
  <div class="content">  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <section id="applications-of-determinants">
<h1>Applications of Determinants<a class="headerlink" href="#applications-of-determinants" title="Permalink to this headline">¶</a></h1>
<section id="examination-of-the-linear-dependence-of-vectors">
<span id="twtest"></span><h2>Examination of the Linear Dependence of Vectors<a class="headerlink" href="#examination-of-the-linear-dependence-of-vectors" title="Permalink to this headline">¶</a></h2>
<div class="admonition-theorem-5-math admonition">
<p class="admonition-title">Theorem 5. <span class="math notranslate nohighlight">\(\\\)</span></p>
<p>The determinant of a matrix vanishes if, and only if,
its columns are linearly dependent.</p>
<p>Thus, if <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\,=\,
[\,\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,
\boldsymbol{A}_n\,]\,\in\,M_n(K),\ \,\)</span> then</p>
<div class="math notranslate nohighlight">
\[\det{\boldsymbol{A}}\,=\,0\qquad\Leftrightarrow\qquad
\boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\ \
\text{are linearly dependent}.\]</div>
</div>
<p><strong>Proof.</strong> <span class="math notranslate nohighlight">\(\,\)</span> Let <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\,=\,
[\,\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,
\boldsymbol{A}_n\,]\,\in\,M_n(K).\)</span></p>
<p><span class="math notranslate nohighlight">\(\Leftarrow\ :\ \ \)</span>
We assume that the columns
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\ \)</span>
are linearly dependent.</p>
<p>Then one of the columns is a linear combination of the remaining ones.
Let for example</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{A}_n\ =\
\lambda_1\,\boldsymbol{A}_1\,+\;\lambda_2\,\boldsymbol{A}_2\,+\;\ldots\,+
\lambda_{n-1}\,\boldsymbol{A}_{n-1}\,.\]</div>
<p>On the basis of Postulates <span class="math notranslate nohighlight">\(\,\)</span> 1. <span class="math notranslate nohighlight">\(\,\)</span> and
<span class="math notranslate nohighlight">\(\,\)</span> 2. <span class="math notranslate nohighlight">\(\,\)</span> of the axiomatic definition, we obtain</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\det{\boldsymbol{A}}\ \ =\ \ \det{\,[\,
\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,\boldsymbol{A}_{n-1}\,|\;
\lambda_1\,\boldsymbol{A}_1\,+\,\lambda_2\,\boldsymbol{A}_2\,+\,\ldots\,+\,
\lambda_{n-1}\,\boldsymbol{A}_{n-1}\,]}\ \ =\\=\ \
\lambda_1\,\det{\,[\,\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,
\boldsymbol{A}_{n-1}\,|\,\boldsymbol{A}_1\,]}\ \ +\\+\ \
\lambda_2\,\det{\,[\,\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,
\boldsymbol{A}_{n-1}\,|\,\boldsymbol{A}_2\,]}\ \ +\\\ldots\\+\ \
\lambda_{n-1}\,\det{\,[\,\boldsymbol{A}_1\,|\;\boldsymbol{A}_2\,|\,\dots\,|\,
\boldsymbol{A}_{n-1}\,|\,\boldsymbol{A}_{n-1}\,]}\,.\end{aligned}\end{align} \]</div>
<p>Each out of the <span class="math notranslate nohighlight">\(\,n-1\,\)</span> components in the last sum
is proportional to a determinant with two identical columns.
Thus, recalling Property IIIa., we infer that <span class="math notranslate nohighlight">\(\ \det\boldsymbol{A} = 0.\)</span></p>
<p><span class="math notranslate nohighlight">\(\,\)</span></p>
<p><span class="math notranslate nohighlight">\(\Rightarrow\ :\ \ \)</span>
We assume that the columns
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\ \)</span>
of the matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\,\)</span> are linearly independent.</p>
<p>The number <span class="math notranslate nohighlight">\(\,n\,\)</span> of linearly independent columns being equal
to the dimension of the vector space <span class="math notranslate nohighlight">\(\,K^n\ \)</span> they belong to,
the aforesaid columns form a basis of that space.
Thus every vector in <span class="math notranslate nohighlight">\(\,K^n\ \)</span> can be uniquely represented as
a linear combination of
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\,.\ \)</span></p>
<p>In particular, the vectors <span class="math notranslate nohighlight">\(\,\boldsymbol{e}_j\ \)</span>
of the standard basis of the space <span class="math notranslate nohighlight">\(\,K^n\ \)</span> may be written as</p>
<div class="math notranslate nohighlight" id="equation-eqn-ej">
<span class="eqno">(1)<a class="headerlink" href="#equation-eqn-ej" title="Permalink to this equation">¶</a></span>\[\begin{split}\boldsymbol{e}_j\ \ =\ \ \sum_{s\,=\,1}^n\ b_{sj}\,\boldsymbol{A}_s\,,
\qquad\text{where}\quad\boldsymbol{e}_j\ =\
\left[\begin{array}{c} 0 \\ \dots \\ 1 \\ \dots \\ 0 \end{array}\right]
\leftarrow j\,,\qquad j=1,2,\ldots,n.\end{split}\]</div>
<p>Equations <a class="reference internal" href="#equation-eqn-ej">(1)</a> assert that the <span class="math notranslate nohighlight">\(\,j\)</span>-th column of the identity
matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{I}_n =
[\,\boldsymbol{e}_1\,|\;\boldsymbol{e}_2\,|\,\dots\,|\,\boldsymbol{e}_n\,]\ \)</span>
is a linear combination of columns of matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A},\ \)</span>
with coefficients taken from the <span class="math notranslate nohighlight">\(\,j\)</span>-th column of matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{B}=[b_{ij}]_{n\times n}.\ \)</span>
According to the Column Rule of Matrix Multiplication, this means that
<span class="math notranslate nohighlight">\(\ \boldsymbol{I}_n = \boldsymbol{A}\boldsymbol{B}.\ \)</span></p>
<p>Using the theorem on the determinant of a product of matrices, we may write</p>
<div class="math notranslate nohighlight">
\[\det{\boldsymbol{A}}\,\cdot\,\det{\boldsymbol{B}}\ \ =\ \
\det{\,(\boldsymbol{A}\boldsymbol{B})}\ \ =\ \
\det{\boldsymbol{I}_n}\ =\ 1\,.\]</div>
<p>Hence <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ne 0,\ \,\)</span>
because if there was <span class="math notranslate nohighlight">\(\ \det\boldsymbol{A} = 0,\ \)</span>
it would be <span class="math notranslate nohighlight">\(\ \det\boldsymbol{A}\,\cdot\,\det\boldsymbol{B}\,=\,0.\)</span></p>
<p>So we have proved that</p>
<div class="math notranslate nohighlight">
\[\text{columns}\ \ \boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\ \
\text{are linearly independent}
\quad\Rightarrow\quad
\det{\boldsymbol{A}}\ne 0\,,\]</div>
<p>which is equivalent, by contraposition, to the statement</p>
<div class="math notranslate nohighlight">
\[\det\boldsymbol{A}\ =\ 0
\quad\Rightarrow\quad
\text{columns}\ \ \boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n\ \
\text{are linearly dependent}\,.\quad\bullet\]</div>
<p><strong>Notes and Comments.</strong></p>
<ul>
<li><p>In view of Theorem 3. on invariance of the determinant under matrix’
transpose, <span class="math notranslate nohighlight">\(\\\)</span> Theorem 5. may be rewritten in the row version:</p>
<p>The determinant of a matrix vanishes if, and only if,
its rows are linearly dependent.</p>
</li>
<li><p>Equations <a class="reference internal" href="#equation-eqn-ej">(1)</a> pertain to the situation where in the vector space
<span class="math notranslate nohighlight">\(\,K^n\,\)</span> there are two bases: the basis <span class="math notranslate nohighlight">\(\ \,\mathcal{B}\,=\,
(\boldsymbol{A}_1,\boldsymbol{A}_2,\dots,\boldsymbol{A}_n),\ \,\)</span> composed
of linearly independent columns of matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A},\ \)</span>
and the standard basis <span class="math notranslate nohighlight">\(\ \mathcal{E}\,=\,
(\boldsymbol{e}_1,\boldsymbol{e}_2,\dots,\boldsymbol{e}_n)\,.\)</span></p>
<p>The matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{B}=[\,b_{ij}\,]_{n\times n}\,,\ \)</span>
whose <span class="math notranslate nohighlight">\(\,j\)</span>-th column is composed of the coordinates
of the <span class="math notranslate nohighlight">\(\,j\)</span>-th vector of basis <span class="math notranslate nohighlight">\(\ \mathcal{E}\ \)</span>
in the basis <span class="math notranslate nohighlight">\(\ \mathcal{B}\ \ \ (j=1,2,\ldots,n),\ \,\)</span>
is named the <em>transition matrix</em> from basis <span class="math notranslate nohighlight">\(\,\mathcal{B}\ \)</span>
to basis <span class="math notranslate nohighlight">\(\ \mathcal{E}.\)</span></p>
</li>
</ul>
<p><span class="math notranslate nohighlight">\(\;\)</span></p>
<p><strong>Example 7.</strong> <span class="math notranslate nohighlight">\(\,\)</span> It is to be confirmed that the vectors</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{f}_1\ =\
\left[\begin{array}{c} 1 \\ 0 \\ 0 \\ \dots \\ 0 \end{array}\right]\,,\quad
\boldsymbol{f}_2\ =\
\left[\begin{array}{c} 1 \\ 1 \\ 0 \\ \dots \\ 0 \end{array}\right]\,,\quad
\boldsymbol{f}_3\ =\
\left[\begin{array}{c} 1 \\ 1 \\ 1 \\ \dots \\ 0 \end{array}\right]\,,\quad
\dots,\quad
\boldsymbol{f}_n\ =\
\left[\begin{array}{c} 1 \\ 1 \\ 1 \\ \dots \\ 1 \end{array}\right]\end{split}\]</div>
<p>form a basis in the vector space <span class="math notranslate nohighlight">\(\ K^n.\)</span></p>
<p><strong>Solution.</strong></p>
<p>In an <span class="math notranslate nohighlight">\(\,n\)</span>-dimensional vector space every set of <span class="math notranslate nohighlight">\(\,n\,\)</span>
linearly independent vectors is a basis. <span class="math notranslate nohighlight">\(\\\)</span>
Since <span class="math notranslate nohighlight">\(\,\text{dim}\,K^n=n,\ \)</span>
it is enough to verify the linear independence of vectors
<span class="math notranslate nohighlight">\(\,\boldsymbol{f}_1,\,\boldsymbol{f}_2,\,\ldots,\,\boldsymbol{f}_n.\)</span></p>
<p>Using Theorem 5., we check whether the determinant of the matrix composed
of these <span class="math notranslate nohighlight">\(\,n\,\)</span> column vectors is different from zero.
The matrix being upper triangular, the calculation is trivial,
leading to the positive answer:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\det{\ [\,
\boldsymbol{f}_1\,|\;\boldsymbol{f}_2\,|\,\ldots\,|\,
\boldsymbol{f}_n\,]}\ \ =\ \
\left|
\begin{array}{ccccc}
  1   &amp;   1   &amp;   1   &amp; \dots &amp;   1   \\
  0   &amp;   1   &amp;   1   &amp; \dots &amp;   1   \\
  0   &amp;   0   &amp;   1   &amp; \dots &amp;   1   \\
\dots &amp; \dots &amp; \dots &amp; \dots &amp; \dots \\
  0   &amp;   0   &amp;   0   &amp; \dots &amp;   1
\end{array}
\right|
\ \ =\ \ 1\ne 0\,.\end{split}\]</div>
</section>
<section id="calculation-of-the-inverse-of-a-matrix">
<span id="calc-inv-matrix"></span><h2>Calculation of the Inverse of a Matrix<a class="headerlink" href="#calculation-of-the-inverse-of-a-matrix" title="Permalink to this headline">¶</a></h2>
<div class="admonition-theorem-6-math-generalized-laplace-expansion-math admonition">
<p class="admonition-title">Theorem 6. <span class="math notranslate nohighlight">\(\,\)</span>
Generalized Laplace Expansion. <span class="math notranslate nohighlight">\(\\\)</span></p>
<p>The following relations hold true for a matrix
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}=[\,a_{ij}\,]_{n\times n}\in M_n(K):\)</span></p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}a_{i1}\,A_{j1}\ +\ a_{i2}\,A_{j2}\ +\ \dots\ +\ a_{in}\,A_{jn}\ \ =\ \
\delta_{ij}\,\cdot\,\det\boldsymbol{A}\,,\qquad i,j=1,2,\ldots,n;\\a_{1k}\,A_{1l}\ +\ a_{2k}\,A_{2l}\ +\ \dots\ +\ a_{nk}\,A_{nl}\ \ =\ \
\delta_{kl}\,\cdot\,\det\boldsymbol{A}\,,\qquad k,l=1,2,\ldots,n.\\\begin{split}\text{where}\quad\delta_{pq}\ \,=\ \,
\left\{\
\begin{array}{cc}
1 &amp; \text{for}\ \ p=q, \\ 0 &amp; \text{for}\ \ p\ne q;
\end{array}\right.\qquad
p,q=1,2,\ldots,n.\qquad
\text{(the Kronecker delta)}\end{split}\end{aligned}\end{align} \]</div>
</div>
<p>This may be rewritten more succinctly as</p>
<div class="math notranslate nohighlight" id="equation-lap-exp-gen">
<span class="eqno">(2)<a class="headerlink" href="#equation-lap-exp-gen" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}\sum_{k\,=\,1}^n\ a_{ik}\ A_{jk}\ \ =\ \
\delta_{ij}\,\cdot\,\det\boldsymbol{A}\,,\qquad i,j=1,2,\ldots,n;\qquad
\text{(row version)}\\\sum_{i\,=\,1}^n\ a_{ik}\ A_{il}\ \ =\ \
\delta_{kl}\,\cdot\,\det\boldsymbol{A}\,,\qquad k,l=1,2,\ldots,n;\qquad
\text{(column version)}\end{aligned}\end{align} \]</div>
<p><strong>Interpretation</strong> (row version):</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\ i=j:\ \)</span> The consecutive elements of a selected row of the matrix
are multiplied by <em>their</em> cofactors; <span class="math notranslate nohighlight">\(\,\)</span> the sum of all such
products is equal to the determinant of the matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(\ i\ne j:\ \)</span> The consecutive elements of a selected row
are multiplied by the cofactors of the corresponding elements
<em>in another row</em>; <span class="math notranslate nohighlight">\(\,\)</span> the sum of all such products is equal to zero.</p></li>
</ul>
<p>The column version may be interpreted in an analogous way.</p>
<p><strong>Proof.</strong> <span class="math notranslate nohighlight">\(\,\)</span>
For <span class="math notranslate nohighlight">\(\,i=j\ \)</span> Equation <a class="reference internal" href="#equation-lap-exp-gen">(2)</a> becomes the Laplace expansion
with respect to the <span class="math notranslate nohighlight">\(\ i\)</span>-th row.
So, it is enough to consider the case <span class="math notranslate nohighlight">\(\ i\ne j\ \)</span> only.</p>
<p>Starting from the matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{A}=[\,a_{ij}\,]_{n\times n}\,,\ \)</span>
we create an auxiliary matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{B}=[\,b_{ij}\,]_{n\times n}\,.\)</span>
<span class="math notranslate nohighlight">\(\\\)</span>
<span class="math notranslate nohighlight">\(\ \boldsymbol{B}\ \)</span> differs from <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\ \)</span> only
in the <span class="math notranslate nohighlight">\(\,j\)</span>-th row, which is a repetition of the <span class="math notranslate nohighlight">\(\,i\)</span>-th one:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{A}\ \ =\ \
\left[\begin{array}{c}
      \boldsymbol{A}_1 \\
      \dots            \\
      \boldsymbol{A}_i \\
      \dots            \\
      \boldsymbol{A}_j \\
      \dots            \\
      \boldsymbol{A}_n
      \end{array}
\right]
      \begin{array}{c}
      \;           \\
      \;           \\
      \leftarrow i \\
      \;           \\
      \leftarrow j \\
      \;           \\
      \;
      \end{array}
\qquad\qquad
\boldsymbol{B}\ \ =\ \
\left[\begin{array}{c}
      \boldsymbol{A}_1 \\
      \dots            \\
      \boldsymbol{A}_i \\
      \dots            \\
      \boldsymbol{A}_i \\
      \dots            \\
      \boldsymbol{A}_n
      \end{array}
\right]
      \begin{array}{c}
      \;           \\
      \;           \\
      \leftarrow i \\
      \;           \\
      \leftarrow j \\
      \;           \\
      \;
      \end{array}\end{split}\]</div>
<p>The elements <span class="math notranslate nohighlight">\(\,b_{jk}\,\)</span> and cofactors <span class="math notranslate nohighlight">\(\,B_{jk}\,\)</span> of matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{B}\,\)</span> fulfill the relations</p>
<div class="math notranslate nohighlight" id="equation-elem">
<span class="eqno">(3)<a class="headerlink" href="#equation-elem" title="Permalink to this equation">¶</a></span>\[b_{jk}\,=\,b_{ik}\,=\,a_{ik}\,,
\qquad B_{jk}\,=\,A_{jk}\,,
\qquad k=1,2,\ldots,n.\]</div>
<p>Because of two identical rows, the determinant of matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{B}\,\)</span> equals zero. Taking into account equalities
<a class="reference internal" href="#equation-elem">(3)</a> and expansion of <span class="math notranslate nohighlight">\(\,\det\boldsymbol{B}\ \)</span> with respect
to the <span class="math notranslate nohighlight">\(\,j\)</span>-th row, we obtain</p>
<div class="math notranslate nohighlight">
\[\sum_{k\,=\,1}^n\ a_{ik}\,A_{jk}\ \ =\ \
\sum_{k\,=\,1}^n\ b_{jk}\,B_{jk}\ \ =\ \
\det\boldsymbol{B}\ \ =\ \ 0\,.
\quad\bullet\]</div>
<div class="admonition-definition admonition">
<p class="admonition-title">Definition.</p>
<p>Let <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\in M_n(K)\,.\ \,\)</span>
If <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}=0,\ \,\)</span> then <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\ \,\)</span>
is called <span class="math notranslate nohighlight">\(\,\)</span> a <span class="math notranslate nohighlight">\(\,\)</span> <em>singular matrix</em>. <span class="math notranslate nohighlight">\(\\\)</span>
Otherwise, <span class="math notranslate nohighlight">\(\,\)</span> when <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ne 0,\ \)</span>
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}\ \)</span> is <span class="math notranslate nohighlight">\(\,\)</span> a <span class="math notranslate nohighlight">\(\,\)</span> <em>non-singular matrix</em>.</p>
</div>
<div class="admonition-theorem-7 admonition">
<p class="admonition-title">Theorem 7.</p>
<p>A matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\in M_n(K)\ \,\)</span> is invertible <span class="math notranslate nohighlight">\(\,\)</span>
if, and only if, <span class="math notranslate nohighlight">\(\,\)</span> it is non-singular.</p>
</div>
<p><strong>Proof.</strong></p>
<p><span class="math notranslate nohighlight">\(\Rightarrow\ :\ \)</span>
We assume that there exists the inverse <span class="math notranslate nohighlight">\(\,\boldsymbol{A}^{-1}.\ \,\)</span>
Then</p>
<div class="math notranslate nohighlight">
\[\det\boldsymbol{A}\,\cdot\,\det\boldsymbol{A}^{-1}\ \,=\ \,
\det\,(\boldsymbol{A}\boldsymbol{A}^{-1})\ \,=\ \,
\det\boldsymbol{I}_n\ \,=\ \,1\,.\]</div>
<p>Hence <span class="math notranslate nohighlight">\(\ \det\boldsymbol{A}\ne 0,\ \,\)</span> because
if there was <span class="math notranslate nohighlight">\(\ \det\boldsymbol{A} = 0,\ \,\)</span> there would be
<span class="math notranslate nohighlight">\(\ \det\boldsymbol{A}\,\cdot\,\det\boldsymbol{A}^{-1}\,=\;0.\)</span></p>
<div class="admonition-corollary admonition">
<p class="admonition-title">Corollary.</p>
<p>If a matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\in M_n(K)\ \)</span> is invertible, <span class="math notranslate nohighlight">\(\,\)</span>
then <span class="math notranslate nohighlight">\(\ \,\det\boldsymbol{A}^{-1}\,=\ (\det\boldsymbol{A})^{-1}\,.\)</span></p>
</div>
<p><span class="math notranslate nohighlight">\(\Leftarrow\ :\ \)</span>
We assume that the matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{A}=[\,a_{ij}\,]_{n\times n}\ \)</span>
is non-singular: <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ne 0.\ \)</span>
Then the matrix</p>
<div class="math notranslate nohighlight" id="equation-rec-mat">
<span class="eqno">(4)<a class="headerlink" href="#equation-rec-mat" title="Permalink to this equation">¶</a></span>\[\begin{split}\boldsymbol{B}\ \,:\,=\ \,
\frac{1}{\det\boldsymbol{A}}\
\left[\begin{array}{cccc}
      A_{11} &amp; A_{12} &amp; \dots &amp; A_{1n} \\
      A_{21} &amp; A_{22} &amp; \dots &amp; A_{2n} \\
      \dots  &amp; \dots  &amp; \dots  &amp; \dots \\
      A_{n1} &amp; A_{n2} &amp; \dots &amp; A_{nn}
      \end{array}
\right]^{\,T}=\ \ \,
\frac{1}{\det\boldsymbol{A}}\
\left[\begin{array}{cccc}
      A_{11} &amp; A_{21} &amp; \dots &amp; A_{n1} \\
      A_{12} &amp; A_{22} &amp; \dots &amp; A_{n2} \\
      \dots  &amp; \dots  &amp; \dots  &amp; \dots \\
      A_{1n} &amp; A_{2n} &amp; \dots &amp; A_{nn}
      \end{array}
\right],\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\ A_{ij}\ \)</span> is the cofactor of the element <span class="math notranslate nohighlight">\(\ a_{ij}\,,\ \,\)</span>
is the inverse of matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\,.\)</span></p>
<p>Indeed, elements <span class="math notranslate nohighlight">\(\ b_{ij}\ \)</span> of matrix <span class="math notranslate nohighlight">\(\ \boldsymbol{B}\ \)</span>
are given by</p>
<div class="math notranslate nohighlight">
\[b_{ij}\ \ =\ \
\frac{1}{\det{\boldsymbol{A}}}\ \ A_{ji}\,,\qquad i,j=1,2,\ldots,n.\]</div>
<p>Let
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}\boldsymbol{B}=\boldsymbol{C}=[c_{ij}]_{n\times n}\,,\ \)</span>
<span class="math notranslate nohighlight">\(\ \boldsymbol{B}\boldsymbol{A}=\boldsymbol{C'}=[c_{ij}']_{n\times n}\,.\ \)</span>
Using <a class="reference internal" href="#equation-lap-exp-gen">(2)</a> we get</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}c_{ij}\ \,=\ \ \sum_{s\,=\,1}^n\ a_{is}\,b_{sj}
\ \,=\ \ \frac{1}{\det\boldsymbol{A}}\ \ \sum_{s\,=\,1}^n\ a_{is}\,A_{js}
\ \,=\ \ \frac{1}{\det\boldsymbol{A}}\ \cdot\ \delta_{ij}\,\cdot\ \det\boldsymbol{A}
\ \,=\ \,\delta_{ij}\,,\\c_{ij}'\ \,=\ \ \sum_{s\,=\,1}^n\ b_{is}\,a_{sj}
\ \,=\ \ \frac{1}{\det\boldsymbol{A}}\ \ \sum_{s\,=\,1}^n\ a_{sj}\,A_{si}
\ \,=\ \ \frac{1}{\det\boldsymbol{A}}\ \cdot\ \delta_{ji}\,\cdot\ \det\boldsymbol{A}
\ \,=\ \,\delta_{ij}\,,\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(\ i,j=1,2,\ldots,n.\ \,\)</span> A matrix whose elements are
Kronecker deltas <span class="math notranslate nohighlight">\(\ \delta_{ij}\ \)</span> is the identity matrix. <span class="math notranslate nohighlight">\(\,\)</span>
Thus <span class="math notranslate nohighlight">\(\ \boldsymbol{A}\boldsymbol{B}=\boldsymbol{B}\boldsymbol{A}=
\boldsymbol{I}_n\,,\ \)</span> that is <span class="math notranslate nohighlight">\(\ \boldsymbol{B}=\boldsymbol{A}^{-1}\,.
\quad\bullet\)</span></p>
<div class="admonition-definition admonition">
<p class="admonition-title">Definition.</p>
<p>For <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\in M_n(K),\ \)</span>
the transpose of the cofactor matrix is the
<em>adjugate matrix</em> <span class="math notranslate nohighlight">\(\,\boldsymbol{A}^D:\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{A}^D\ \,:\,=\ \ \,
\left[\begin{array}{cccc}
      A_{11} &amp; A_{12} &amp; \dots &amp; A_{1n} \\
      A_{21} &amp; A_{22} &amp; \dots &amp; A_{2n} \\
      \dots  &amp; \dots  &amp; \dots  &amp; \dots \\
      A_{n1} &amp; A_{n2} &amp; \dots &amp; A_{nn}
      \end{array}
\right]^{\,T}\,=\ \
\left[\begin{array}{cccc}
      A_{11} &amp; A_{21} &amp; \dots &amp; A_{n1} \\
      A_{12} &amp; A_{22} &amp; \dots &amp; A_{n2} \\
      \dots  &amp; \dots  &amp; \dots  &amp; \dots \\
      A_{1n} &amp; A_{2n} &amp; \dots &amp; A_{nn}
      \end{array}
\right]\,.\end{split}\]</div>
</div>
<p>Including the adjugate matrix as an intermediate step,
the procedure of calculating inverse of a matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{A}=[a_{ij}]_{n\times n}\in M_n(K)\ \)</span>
may be divided into four stages:</p>
<ol class="arabic simple" start="0">
<li><p><span class="math notranslate nohighlight">\(\,\)</span> Calculate <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ \,\)</span> and <span class="math notranslate nohighlight">\(\,\)</span>
check whether <span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ne 0\,.\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\,\)</span> Determine the cofactor matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{C}=[\,A_{ij}\,]_{n\times n}\ \)</span>
by replacing <span class="math notranslate nohighlight">\(\,a_{ij}\rightarrow A_{ij}\ \)</span>
in <span class="math notranslate nohighlight">\(\,\boldsymbol{A}.\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\,\)</span> Transpose the cofactor matrix to obtain the adjugate matrix:
<span class="math notranslate nohighlight">\(\,\boldsymbol{A}^D=\boldsymbol{C}^{\,T}.\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\,\)</span> Divide the adjugate matrix by the determinant
of <span class="math notranslate nohighlight">\(\,\boldsymbol{A}:\ \)</span> <span class="math notranslate nohighlight">\(\ \boldsymbol{A}^{-1}\ =\ \,
\frac{1}{\det{\boldsymbol{A}}}\ \ \boldsymbol{A}^D.\)</span> <span class="math notranslate nohighlight">\(\\\)</span></p></li>
</ol>
<p><strong>Example 8.</strong> <span class="math notranslate nohighlight">\(\,\)</span>
We shall calculate the inverse of the matrix
<span class="math notranslate nohighlight">\(\ \ \boldsymbol{A}\ =\
\left[\begin{array}{rrr}
2 &amp; 2 &amp; 3 \\ 1 &amp; -1 &amp; 0 \\ -1 &amp; 2 &amp; 1
\end{array}\right]\ \in M_3(Q)\,.\)</span></p>
<p><span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ =\
\left|\begin{array}{rrr}
2 &amp; 2 &amp; 3 \\ 1 &amp; -1 &amp; 0 \\ -1 &amp; 2 &amp; 1
\end{array}\right|\ =\
\left|\begin{array}{rrr}
2 &amp; 4 &amp; 3 \\ 1 &amp;  0 &amp; 0 \\ -1 &amp; 1 &amp; 1
\end{array}\right|\ =\
-\ \left|\begin{array}{cc}
4 &amp; 3 \\ 1 &amp; 1 \end{array}\right|\ =\ -1\,.\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{lll}
A_{11}=+\left|\begin{array}{rr} -1 &amp;  0 \\  2 &amp;  1 \end{array}\right|\ =\ -1\,; &amp;
A_{12}=-\left|\begin{array}{rr}  1 &amp;  0 \\ -1 &amp;  1 \end{array}\right|\ =\ -1\,; &amp;
A_{13}=+\left|\begin{array}{rr}  1 &amp; -1 \\ -1 &amp;  2 \end{array}\right|\ =\ 1\,; \\ \\
A_{21}=-\left|\begin{array}{rr}  2 &amp;  3 \\  2 &amp;  1 \end{array}\right|\ =\ 4\,; &amp;
A_{22}=+\left|\begin{array}{rr}  2 &amp;  3 \\ -1 &amp;  1 \end{array}\right|\ =\ 5\,; &amp;
A_{23}=-\left|\begin{array}{rr}  2 &amp;  2 \\ -1 &amp;  2 \end{array}\right|\ =\ -6\,; \\ \\
A_{31}=+\left|\begin{array}{rr}  2 &amp;  3 \\ -1 &amp;  0 \end{array}\right|\ =\ 3\,; &amp;
A_{32}=-\left|\begin{array}{rr}  2 &amp;  3 \\  1 &amp;  0 \end{array}\right|\ =\ 3\,; &amp;
A_{33}=+\left|\begin{array}{rr}  2 &amp;  2 \\  1 &amp; -1 \end{array}\right|\ =\ -4\,.
\end{array}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\begin{array}{l}
\boldsymbol{A}^D\ \ =\ \
\left[\begin{array}{rrr}
      -1 &amp; -1 &amp;  1 \\
       4 &amp;  5 &amp; -6 \\
       3 &amp;  3 &amp; -4
      \end{array}
\right]^{\,T}=\ \ \,
\left[\begin{array}{rrr}
       -1 &amp;  4 &amp;  3 \\
       -1 &amp;  5 &amp;  3 \\
        1 &amp; -6 &amp; -4
      \end{array}
\right]\,;
\\ \\
\displaystyle
\boldsymbol{A}^{-1}\ \ =\ \ \,
\frac{1}{(-1)}\
\left[\begin{array}{rrr}
       -1 &amp;  4 &amp;  3 \\
       -1 &amp;  5 &amp;  3 \\
        1 &amp; -6 &amp; -4
      \end{array}
\right]\ \ =\ \
\left[\begin{array}{rrr}
        1 &amp; -4 &amp; -3 \\
        1 &amp; -5 &amp; -3 \\
       -1 &amp;  6 &amp;  4
      \end{array}
\right]\,.
\end{array}\end{split}\\\;\end{aligned}\end{align} \]</div>
<p>The method <span class="math notranslate nohighlight">\(\,\)</span> <code class="docutils literal notranslate"><span class="pre">inverse()</span></code> <span class="math notranslate nohighlight">\(\,\)</span> of Sage returns the inverse
of a given non-singular square matrix. It may be applied both to numeric
as well as symbolic matrices.</p>
<div class="admonition-experiment-with-sage admonition">
<p class="admonition-title">Experiment with Sage:</p>
<p>Given the matrix size <span class="math notranslate nohighlight">\(\,n\)</span>, the program displays
in the symbolic form a square matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{A}=[a_{ij}]_{n\times n}\ \)</span>
and its inverse. According to the general formulas, the denominators
of the inverse matrix elements contain the determinant of
<span class="math notranslate nohighlight">\(\,\boldsymbol{A},\)</span> whereas the numerators are the appropriate
cofactors.</p>
</div>
<div class='sage_linked'><script type='text/x-sage'>n = 2
A = matrix([[var('a%d%d' % (i,j)) for j in range(1,n+1)]
                                  for i in range(1,n+1)])
show(A)
show(A.inverse().factor())</script></div></section>
<section id="cramer-s-rule-to-solve-systems-of-linear-equations">
<h2>Cramer’s Rule to Solve Systems of Linear Equations<a class="headerlink" href="#cramer-s-rule-to-solve-systems-of-linear-equations" title="Permalink to this headline">¶</a></h2>
<p>We shall consider a system of <span class="math notranslate nohighlight">\(\,n\,\)</span> linear equations
in <span class="math notranslate nohighlight">\(\,n\,\)</span> unknowns over a field <span class="math notranslate nohighlight">\(\,K\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-cramer-0">
<span class="eqno">(5)<a class="headerlink" href="#equation-cramer-0" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{array}{c}
a_{11}\,x_1\; + \ \,a_{12}\,x_2\; + \ \,\ldots\  + \ \;a_{1n}\,x_n \ \, = \ \ b_1 \\
a_{21}\,x_1\; + \ \,a_{22}\,x_2\; + \ \,\ldots\  + \ \;a_{2n}\,x_n \ \, = \ \ b_2 \\
\quad\,\ldots\qquad\quad\ldots\qquad\ \,\ldots\qquad\ \ \ldots\qquad\ \ \,\ldots  \\
a_{n1}\,x_1\; + \ \,a_{n2}\,x_2\; + \ \,\ldots\  + \ \;a_{nn}\,x_n \ \, = \ \ b_n
\end{array}\end{split}\]</div>
<p>with a non-singular (square) coefficient matrix
<span class="math notranslate nohighlight">\(\ \boldsymbol{A}=[a_{ij}]_{n\times n}:\ \)</span>
<span class="math notranslate nohighlight">\(\ \det{\boldsymbol{A}}\ne 0.\)</span></p>
<p>Rewriting the system <a class="reference internal" href="#equation-cramer-0">(5)</a> in the matrix form</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{A}\,\boldsymbol{x}\ =\ \boldsymbol{b}\,,\]</div>
<p>and pre-multiplying the both sides by <span class="math notranslate nohighlight">\(\ \boldsymbol{A}^{-1},\ \)</span>
we get at once the solution:</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{x}\ =\ \boldsymbol{A}^{-1}\,\boldsymbol{b}\,.\]</div>
<p>To derive a practical formula for particular unknowns,
we shall make use of the expression <a class="reference internal" href="#equation-rec-mat">(4)</a> for the inverse matrix:</p>
<div class="math notranslate nohighlight">
\begin{eqnarray*}
\left[\begin{array}{c} x_1 \\ x_2 \\ \dots \\ x_n \end{array}\right]
&amp; = &amp;
\frac{1}{\det\boldsymbol{A}}\
\left[\begin{array}{cccc}
      A_{11} &amp; A_{21} &amp; \dots &amp; A_{n1} \\
      A_{12} &amp; A_{22} &amp; \dots &amp; A_{n2} \\
      \dots  &amp; \dots  &amp; \dots  &amp; \dots \\
      A_{1n} &amp; A_{2n} &amp; \dots &amp; A_{nn}
      \end{array}
\right]\
\left[\begin{array}{c} b_1 \\ b_2 \\ \dots \\ b_n \end{array}\right] \\ \\
&amp; = &amp;
\frac{1}{\det\boldsymbol{A}}\
\left[\begin{array}{c}
      A_{11}\,b_1\ +\ A_{21}\,b_2\ +\ \dots\ +\ A_{n1}\,b_n \\
      A_{12}\,b_1\ +\ A_{22}\,b_2\ +\ \dots\ +\ A_{n2}\,b_n \\
      \dots\qquad\ \ \dots\qquad\ \dots\qquad\dots                \\
      A_{1n}\,b_1\ +\ A_{2n}\,b_2\ +\ \dots\ +\ A_{nn}\,b_n
      \end{array}
\right]\,.
\end{eqnarray*}</div><p>Equating the respective coordinates of the column vectors on both sides
of the equation, <span class="math notranslate nohighlight">\(\\\)</span>
we come up with the explicit formula for <span class="math notranslate nohighlight">\(\,x_j,\ \ j=1,2,\ldots,n:\)</span></p>
<div class="math notranslate nohighlight">
\begin{eqnarray*}
x_j &amp; = &amp; \frac{1}{\det\boldsymbol{A}}\ \
          (b_1\,A_{1j}\ +\ b_2\,A_{2j}\ +\ \dots\ +\ b_n\,A_{nj}) \\
&amp; = &amp;
\frac{1}{\det\boldsymbol{A}}\ \
\left|\begin{array}{ccccccc}
      a_{11} &amp; \dots &amp; a_{1,j-1} &amp;  b_1  &amp; a_{1,j+1} &amp; \dots &amp; a_{1n} \\
      a_{21} &amp; \dots &amp; a_{2,j-1} &amp;  b_2  &amp; a_{2,j+1} &amp; \dots &amp; a_{2n} \\
      \dots  &amp; \dots &amp;  \dots    &amp; \dots &amp;  \dots    &amp; \dots &amp; \dots  \\
      a_{n1} &amp; \dots &amp; a_{n,j-1} &amp;  b_n  &amp; a_{n,j+1} &amp; \dots &amp; a_{nn}
      \end{array}
\right|\,,\qquad j=1,2,\ldots,n.
\end{eqnarray*}</div><div class="admonition-theorem-8-math-the-cramer-s-rule admonition">
<p class="admonition-title">Theorem 8. <span class="math notranslate nohighlight">\(\,\)</span> The Cramer’s Rule.</p>
<p>The linear system <a class="reference internal" href="#equation-cramer-0">(5)</a> has the unique solution given by</p>
<div class="math notranslate nohighlight">
\[x_j\ \ =\ \ \frac{D_j}{D}\,,\qquad j=1,2,\ldots,n,\]</div>
<p>where <span class="math notranslate nohighlight">\(\,D\,\)</span> is the determinant of the coefficient matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{A},\ \)</span> and <span class="math notranslate nohighlight">\(\,D_j\,\)</span> is the determinant
of the matrix obtained from <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\ \)</span> by replacing
the <span class="math notranslate nohighlight">\(\,j\)</span>-th column with the column of constants
<span class="math notranslate nohighlight">\(\,\boldsymbol{b}.\ \)</span>  Using the column notation of matrices,
this may be written as</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}D\ \,=\ \,\det\;[\;\boldsymbol{A}_1\,|\,\dots\,|\,
\boldsymbol{A}_j\,|\,\dots\,|\,\boldsymbol{A}_n\,]\,,\\D_j\ =\ \,\det\;[\;\boldsymbol{A}_1\,|\,\dots\,|\
\boldsymbol{b}\,|\ \dots\,|\,\boldsymbol{A}_n\,]\,.\end{aligned}\end{align} \]</div>
</div>
<p><strong>Example 9.</strong> <span class="math notranslate nohighlight">\(\,\)</span>
Consider the system of 3 equations in 3 unknowns
over the rational field <span class="math notranslate nohighlight">\(\,Q:\)</span></p>
<div class="math notranslate nohighlight">
\begin{alignat*}{4}
2\,x_1 &amp; {\,} - {\,} &amp;    x_2 &amp; {\,} - {\,} &amp;    x_3 &amp; {\;} = {} &amp;  4 \\
3\,x_1 &amp; {\,} + {\,} &amp; 4\,x_2 &amp; {\,} - {\,} &amp; 2\,x_3 &amp; {\;} = {} &amp; 11 \\
3\,x_1 &amp; {\,} - {\,} &amp; 2\,x_2 &amp; {\,} + {\,} &amp; 4\,x_3 &amp; {\;} = {} &amp; 11
\end{alignat*}</div><p>When in a given system the number of equations equals the number of unknowns
(the coefficient matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A}\,\)</span> is square), then we begin
with the calculation of <span class="math notranslate nohighlight">\(\ D=\det\boldsymbol{A}.\ \)</span> In this case</p>
<div class="math notranslate nohighlight">
\[\begin{split}D\ =\
\left|\begin{array}{rrr} 2 &amp; -1 &amp; -1 \\  3 &amp; 4 &amp; -2 \\  3 &amp; -2 &amp; 4 \end{array}\right|\ =\
\left|\begin{array}{rrr} 0 &amp;  0 &amp; -1 \\ -1 &amp; 6 &amp; -2 \\ 11 &amp; -6 &amp; 4 \end{array}\right|\ =\
-\ \left|\begin{array}{rr} -1 &amp; 6 \\  11 &amp; -6 \end{array}\right|\ =\
6\ \left|\begin{array}{rr}  1 &amp; 1 \\ -11 &amp; -1 \end{array}\right|\ =\ 60\,.\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\,D\ne 0,\ \)</span> we calculate the determinants <span class="math notranslate nohighlight">\(\,D_1,\,D_2\,\)</span>
and <span class="math notranslate nohighlight">\(\,D_3\,\)</span> in the Cramer’s rule:</p>
<p><span class="math notranslate nohighlight">\(D_1\ =\
\left|\begin{array}{rrr} 4 &amp; -1 &amp; -1 \\ 11 &amp; 4 &amp; -2 \\ 11 &amp; -2 &amp; 4 \end{array}\right|\ =\
\left|\begin{array}{rrr} 0 &amp;  0 &amp; -1 \\  3 &amp; 6 &amp; -2 \\ 27 &amp; -6 &amp; 4 \end{array}\right|\ =\
-\ \left|\begin{array}{rr} 3 &amp;  6 \\ 27 &amp; -6 \end{array}\right|\ =\
18\ \left|\begin{array}{rr} 1 &amp; -1 \\  9 &amp;  1 \end{array}\right|\ =\ 180\,,\)</span></p>
<p><span class="math notranslate nohighlight">\(D_2\ =\
\left|\begin{array}{rrr} 2 &amp; 4 &amp; -1 \\  3 &amp; 11 &amp; -2 \\  3 &amp; 11 &amp; 4 \end{array}\right|\ =\
\left|\begin{array}{rrr} 0 &amp; 0 &amp; -1 \\ -1 &amp;  3 &amp; -2 \\ 11 &amp; 27 &amp; 4 \end{array}\right|\ =\
-\ \left|\begin{array}{rr} -1 &amp; 3 \\  11 &amp; 27 \end{array}\right|\ =\
3\ \left|\begin{array}{rr}  1 &amp; 1 \\ -11 &amp;  9 \end{array}\right|\ =\ 60\,,\)</span></p>
<p><span class="math notranslate nohighlight">\(D_3\ =\
\left|\begin{array}{rrr} 2 &amp; -1 &amp; 4 \\  3 &amp; 4 &amp; 11 \\  3 &amp; -2 &amp; 11 \end{array}\right|\ =\
\left|\begin{array}{rrr} 0 &amp; -1 &amp; 0 \\ 11 &amp; 4 &amp; 27 \\ -1 &amp; -2 &amp;  3 \end{array}\right|\ =\
\left|\begin{array}{rr} 11 &amp; 27 \\ -1 &amp; 3 \end{array}\right|\ =\
3\ \left|\begin{array}{rr} 11 &amp;  9 \\ -1 &amp; 1 \end{array}\right|\ =\ 60\,.\)</span></p>
<p>Finally, the system has the unique solution:</p>
<div class="math notranslate nohighlight">
\[x_1\ =\ \textstyle{180\over 60}\ =\ 3\,,\quad
x_2\ =\ \textstyle{60\over 60}\ =\ 1\,,\quad
x_3\ =\ \textstyle{60\over 60}\ =\ 1\,.\]</div>
<p>In Sage, the formulas of the Cramer’s rule may be obtained also in symbolic
form for any size <span class="math notranslate nohighlight">\(\,n=2,3,\ldots\ \)</span> of matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{A}.\ \)</span>
Namely, the solution of the system is given by the last column of the augmented
matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{B}=[\,\boldsymbol{A}\,|\,\boldsymbol{b}\,]\ \)</span>
transformed to the reduced row echelon form.</p>
<div class="admonition-experiment-with-sage admonition">
<p class="admonition-title">Experiment with Sage:</p>
<p>Given the size <span class="math notranslate nohighlight">\(\,n\,\)</span> of the coefficient matrix
<span class="math notranslate nohighlight">\(\,\boldsymbol{A},\ \)</span> the following program displays
the augmented matrix <span class="math notranslate nohighlight">\(\,\boldsymbol{B}\ \)</span> in its original
and row-reduced echelon form. Elements of the last column of
the latter matrix, which provide the solution, are displayed
additionally enlarged for a better readability.</p>
</div>
<div class='sage_linked'><script type='text/x-sage'>n = 2

A = matrix([[var('a%d%d' % (i,j)) for j in range(1,n+1)]
                                  for i in range(1,n+1)])

b = vector([var('b%d' % j) for j in range(1,n+1)])

B = A.augment(b);
R = B.rref().factor()
B.subdivide(n,n); R.subdivide(n,n)

show(table([[B, '$\\rightarrow$', R]]))
for i in range(n): show(R[i,n])</script></div></section>
</section>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div class="sphinxlocaltoc">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Applications of Determinants</a><ul>
<li><a class="reference internal" href="#examination-of-the-linear-dependence-of-vectors">Examination of the Linear Dependence of Vectors</a></li>
<li><a class="reference internal" href="#calculation-of-the-inverse-of-a-matrix">Calculation of the Inverse of a Matrix</a></li>
<li><a class="reference internal" href="#cramer-s-rule-to-solve-systems-of-linear-equations">Cramer’s Rule to Solve Systems of Linear Equations</a></li>
</ul>
</li>
</ul>

  </div>
  <h4>Previous topic</h4>
  <p class="topless"><a href="determinants_practical-calculation.html"
                        title="previous chapter">Practical Calculation of Determinants</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="operations_app_Hill_cipher.html"
                        title="next chapter">Application to Hill Cipher</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/determinants_applications.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  </div>
  <div class="relbar-bottom">
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="operations_app_Hill_cipher.html" title="Application to Hill Cipher"
             >next</a> &nbsp; &nbsp;</li>
        <li class="right" >
          <a href="determinants_practical-calculation.html" title="Practical Calculation of Determinants"
             >previous</a> &nbsp; &nbsp;</li>
  <li><a href="index.html">Linear Algebra</a> &#187;</li>
  
        <li class="nav-item nav-item-this"><a href="">Applications of Determinants</a></li> 
      </ul>
    </div>
  </div>
  
  <div class="footer">
    <a class="logo" href="http://icse.us.edu.pl/" target="_blank"><img src="_static/logo-icse.png" alt="ICSE"/></a><br/>
    &copy; Copyright 2018, Jan Aksamit, Joanna Marzec, and  Marcin Kostur.
    Last updated on Jan 29, 2022.
    Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.1.
  </div>
  </body>
</html>